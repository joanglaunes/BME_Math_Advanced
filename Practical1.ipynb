{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joanglaunes/BME_Math_Advanced/blob/main/Practical1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4af3821c-bfac-4072-83e8-7e7be9d95678",
      "metadata": {
        "id": "4af3821c-bfac-4072-83e8-7e7be9d95678"
      },
      "source": [
        "## BME-Paris Master - UE Math 2 ##\n",
        "# Practical session 1 : signal and image denoising #\n",
        "\n",
        "In this session we will use\n",
        "differential calculus and gradient descent to perform\n",
        "denoising of signals and images.\n",
        "\n",
        "We first download the auxiliary files and import the relevent packages :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35c92627-36ba-479f-96a8-486af7c2d752",
      "metadata": {
        "id": "35c92627-36ba-479f-96a8-486af7c2d752"
      },
      "outputs": [],
      "source": [
        "!wget -q https://github.com/joanglaunes/BME_Math_Advanced/blob/main/brain.png?raw=true -O brain.png\n",
        "!wget -q https://raw.githubusercontent.com/joanglaunes/BME_Math_Advanced/refs/heads/main/autodiff.py\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9df58873-4e86-4cf8-8db6-67d05ec46ae7",
      "metadata": {
        "id": "9df58873-4e86-4cf8-8db6-67d05ec46ae7"
      },
      "source": [
        "We load the test image\n",
        "`brain.png` and display it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92cbe24c-9e0f-4f3b-a994-eb19d5033c67",
      "metadata": {
        "id": "92cbe24c-9e0f-4f3b-a994-eb19d5033c67"
      },
      "outputs": [],
      "source": [
        "# load the image file into the Python session\n",
        "v_org = plt.imread('brain.png')\n",
        "\n",
        "# display the image and add a title\n",
        "plt.imshow(v_org, cmap='gray', vmin=0, vmax=1)\n",
        "plt.title('original image');"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0aa68510-8a6d-4402-97fe-69e6ce86e20a",
      "metadata": {
        "id": "0aa68510-8a6d-4402-97fe-69e6ce86e20a"
      },
      "source": [
        "Now we can add noise to simulate a bad acquisition:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "435129c5-41a2-4e9a-8887-7fc84654b9b5",
      "metadata": {
        "id": "435129c5-41a2-4e9a-8887-7fc84654b9b5"
      },
      "outputs": [],
      "source": [
        "# add random white noise with normal distribution of standard deviation 0.1\n",
        "v = v_org + 0.1 * np.random.randn(*v_org.shape);\n",
        "\n",
        "# display the image\n",
        "plt.imshow(v, cmap='gray', vmin=0, vmax=1)\n",
        "plt.title('noisy image');"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68294317-0803-45bd-b6d4-f5d6d6cc14c4",
      "metadata": {
        "id": "68294317-0803-45bd-b6d4-f5d6d6cc14c4"
      },
      "source": [
        "In a first part we will concentrate on denoising a single row of the image. Such a signal can be extracted from the images and plotted as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77b6c49a-3456-4317-8898-6198b401abea",
      "metadata": {
        "id": "77b6c49a-3456-4317-8898-6198b401abea"
      },
      "outputs": [],
      "source": [
        "# extract row 150 of the noisy image\n",
        "y = v[150,:]\n",
        "# extract row 150 of the original image\n",
        "y_org = v_org[150,:];\n",
        "\n",
        "# display the signals\n",
        "plt.plot(y)\n",
        "plt.plot(y_org)\n",
        "plt.legend(('noisy signal','original signal'));"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8181cfbf-d1cf-41fc-9d12-167174ca52ca",
      "metadata": {
        "id": "8181cfbf-d1cf-41fc-9d12-167174ca52ca"
      },
      "source": [
        "## 1D signal denoising ##\n",
        "\n",
        "$\\newcommand{\\R}{{\\mathbb R}}$\n",
        "Let $y=(y_1,y_2,\\ldots,y_n)\\in\\R^n$ be a discrete 1D signal, which we suppose to be noisy. We will first denoise this signal by minimizing the following function:\n",
        "we define for every $x\\in\\R^n$,\n",
        "$$f(x)=\\sum_{i=1}^n(x_i-y_i)^2+\\alpha\\sum_{i=1}^{n-1}(x_{i+1}-x_i)^2,$$\n",
        "where $\\alpha>0$\n",
        "is a fixed parameter.\n",
        "Minimization of this function will be performed using the gradient descent algorithm with fixed stepsize.\n",
        "\n",
        "To go further we need to write the function which will compute the value of the functional and get its gradient.\n",
        "\n",
        "**Question 1:** Write a function `f(x,y,alpha)`\n",
        "which computes the value of $f(x)$ for an input vector $x$.  Using vector functions `np.diff` and `np.sum`\n",
        ",  you can avoid using any loop. This will result in a much more concise and also faster code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "701bb0a3-5873-4074-a181-60ed3972f5ca",
      "metadata": {
        "id": "701bb0a3-5873-4074-a181-60ed3972f5ca"
      },
      "outputs": [],
      "source": [
        "def f(x,y,alpha):\n",
        "    ### to do ###\n",
        "\n",
        "# example of use : we compute the value of function f when alpha=0.1 and with x=y_org :\n",
        "print(f(y_org,y,0.1))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e86ff43-3c8a-4fe6-a2ea-5df2314cf727",
      "metadata": {
        "id": "5e86ff43-3c8a-4fe6-a2ea-5df2314cf727"
      },
      "source": [
        "Using the automatic differentiation tool `autodiff`, we can avoid to write the expression of the derivatives, and directly compute the gradient of function $f(x)$ as follows :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2151d2cf-71d1-47e8-8b8b-18d22b39b85b",
      "metadata": {
        "id": "2151d2cf-71d1-47e8-8b8b-18d22b39b85b"
      },
      "outputs": [],
      "source": [
        "from autodiff import grad\n",
        "\n",
        "g=grad(f)(y_org,y,0.1) # this computes the gradient of f with respect to the first input\n",
        "g"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30a3a918-f359-4a0e-9949-8783f800ab0c",
      "metadata": {
        "id": "30a3a918-f359-4a0e-9949-8783f800ab0c"
      },
      "source": [
        "We can now try the gradient descent algorithm and visualize the result.\n",
        "\n",
        "**Question 2:** Write a script which performs $N=100$ iterations of the gradient descent algorithm on $f$ with $\\alpha=5$ and stepsize $\\eta=0.01$, and plot the denoised signal `x`. Additionally you can store the sequence of values of the functional at each iteration and plot it in a separate figure. Also try different values for the parameter $\\alpha$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cfa68f2-7811-4e20-90bd-a8203a3698a8",
      "metadata": {
        "id": "1cfa68f2-7811-4e20-90bd-a8203a3698a8"
      },
      "outputs": [],
      "source": [
        "# set parameters\n",
        "N = 100\n",
        "alpha = 5\n",
        "eta = 0.01\n",
        "\n",
        "# perform gradient descent\n",
        "### to do ###\n",
        "\n",
        "# plot results\n",
        "plt.plot(y)\n",
        "plt.plot(x)\n",
        "plt.legend(('noisy','denoised'))\n",
        "plt.show()\n",
        "\n",
        "plt.plot(values_f);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "210de559-166d-4544-b190-40c809ce705c",
      "metadata": {
        "id": "210de559-166d-4544-b190-40c809ce705c"
      },
      "source": [
        "**Question 3:** In this question we will show that gradient descent was in fact not needed for minimizing the function $f$, because the minimizer can be found by looking at optimality conditions.\n",
        "- Show that $f(x)$ can be written in the form $f(x)=\\|x-y\\|^2+\\lambda\\|Ax\\|^2$, where $A$ is a $(n-1)\\times n$ matrix to be found.\n",
        "- Compute the expression of the gradient $\\nabla f(x)$.\n",
        "- Show that the equation $\\nabla f(x)=0$ leads to a linear system which can be written in matrix form $Mx=b$, for some matrix $M$ and vector $b$.\n",
        "- Use Python to solve the system and plot the signal $x$ found.\n",
        "- Explain why this $x$ (solution of $Mx=b$) is the global minimizer of $f$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "facb41f4-6909-48a6-826b-379a7be07bec",
      "metadata": {
        "id": "facb41f4-6909-48a6-826b-379a7be07bec"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now consider an alternative function $h$ to be minimized for denoising the signal:\n",
        "$$h(x)=\\sum_{i=1}^n(x_i-y_i)^2+\\alpha\\sum_{i=1}^{n-1}\\sqrt{\\varepsilon+(x_{i+1}-x_i)^2},$$\n",
        "where $\\varepsilon>0$\n",
        "is another positive parameter (supposed to be close to $0$).\n",
        "\n",
        "Minimizing $h$ instead of $f$ will give a different denoised signal, with different properties. The real benefit of using $h$ instead of $f$ will be clear when dealing with images in the next part.\n",
        "\n",
        "To minimize $h$, the direct approach as in question 3 is no longer possible, so we will use gradient descent.\n",
        "\n",
        "**Question 4:** Proceed as in questions 1 and 2, replacing function $f$ by this new function $h$. Perform $N=500$ iterations of the gradient descent on $h$ with these choices of parameters: $\\alpha=0.5$, $\\eta=0.001$ and $\\varepsilon=10^{-8}$. Plot the denoised signal and compare with the previous result."
      ],
      "metadata": {
        "id": "3zpLgaTgQOkW"
      },
      "id": "3zpLgaTgQOkW"
    },
    {
      "cell_type": "code",
      "source": [
        "### to do ###"
      ],
      "metadata": {
        "id": "BSjF2xKgTKOo"
      },
      "id": "BSjF2xKgTKOo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "2b7f83a7-5dbd-477d-a56d-46e7d7ec7025",
      "metadata": {
        "id": "2b7f83a7-5dbd-477d-a56d-46e7d7ec7025"
      },
      "source": [
        "## Image denoising ##\n",
        "\n",
        "$\\newcommand{\\eps}{\\varepsilon}$\n",
        "\n",
        "In this part signals will be 2D grayscale images. $u=(u_{ij})\\in\\R^{m\\times n}$, where $u_{ij}$ gives intensity at pixel $(i,j)$. If $v=(v_{ij})$ is the noisy image, we now define:\n",
        "\\begin{eqnarray*} f(u)&=&\\sum_{i=1}^m\\sum_{j=1}^n(u_{ij}-v_{ij})^2+\\alpha\\sum_{i=1}^{m-1}\\sum_{j=1}^{n-1}(u_{i+1,j}-u_{ij})^2+(u_{i,j+1}-u_{ij})^2,\\\\\\\\ h(u)&=&\\sum_{i=1}^m\\sum_{j=1}^n(u_{ij}-v_{ij})^2+\\alpha\\sum_{i=1}^{m-1}\\sum_{j=1}^{n-1}\\sqrt{\\eps+(u_{i+1,j}-u_{ij})^2+(u_{i,j+1}-u_{ij})^2},\\end{eqnarray*}\n",
        "\n",
        "**Question 4:** Proceed as in the first part: write new functions `f` and `h` corresponding to this 2D case, and write gradient descent algorithms for the two functions. You can use the following parameters : $N=100$, $\\alpha=1$, $\\eta=0.01$ for $f$, and $N=200$, $\\alpha=0.1$, $\\eta=0.01$, $\\eps=10^{-4}$ for $h$. Test the algorithms on the noisy image of the brain $v$ and\n",
        "compare the two approaches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d001adb4-79ed-40dd-a2ec-5848d6381cd5",
      "metadata": {
        "id": "d001adb4-79ed-40dd-a2ec-5848d6381cd5"
      },
      "outputs": [],
      "source": [
        "def f(u,v,alpha):\n",
        "    ### to do ###\n",
        "\n",
        "# parameters\n",
        "N = 100\n",
        "alpha = 1\n",
        "eta = 0.01\n",
        "\n",
        "# gradient descent\n",
        "### to do ###\n",
        "\n",
        "# display images\n",
        "plt.imshow(v, cmap='gray', vmin=0, vmax=1)\n",
        "plt.title('noisy')\n",
        "plt.show()\n",
        "plt.imshow(u, cmap='gray', vmin=0, vmax=1)\n",
        "plt.title('denoised')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(values_f);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d1e99f0-a01b-491b-b40f-c8a2e0c6e35c",
      "metadata": {
        "id": "3d1e99f0-a01b-491b-b40f-c8a2e0c6e35c"
      },
      "outputs": [],
      "source": [
        "def h(u,v,alpha,epsilon):\n",
        "    ### to do ###\n",
        "\n",
        "# parameters\n",
        "N = 200\n",
        "alpha = 0.1\n",
        "epsilon = 1e-4\n",
        "eta = 0.01\n",
        "\n",
        "# gradient descent\n",
        "### to do ###\n",
        "\n",
        "# display images\n",
        "plt.imshow(v, cmap='gray', vmin=0, vmax=1)\n",
        "plt.title('noisy')\n",
        "plt.show()\n",
        "plt.imshow(u, cmap='gray', vmin=0, vmax=1)\n",
        "plt.title('denoised')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(values_h);"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WXEQNUC8VTZW"
      },
      "id": "WXEQNUC8VTZW",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}